#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
ARG spark_py_image
FROM ${spark_py_image} AS noscience

ARG spark_uid=185
ENV spark_uid=${spark_uid}

ARG input_survey
ENV input_survey=${input_survey}
ENV FINK_BROKER_ROOT=/opt/fink-broker

# Install system-dependencies and prepare spark_uid user home directory
USER root

RUN apt-get update && \
    apt install -y --no-install-recommends wget git apt-transport-https ca-certificates gnupg-agent apt-utils build-essential && \
    rm -rf /var/cache/apt/*

# Download and install Spark dependencies listed in jars-urls.txt
RUN mkdir -p $FINK_BROKER_ROOT/k8s && chown ${spark_uid} $FINK_BROKER_ROOT
ADD containerfs/k8s/jars-urls.txt $FINK_BROKER_ROOT/k8s/
RUN xargs -n 1 curl --fail --output-dir /opt/spark/jars -O < $FINK_BROKER_ROOT/k8s/jars-urls.txt


# Setup for the Prometheus JMX exporter.
# TODO:
# 1. check
# jmx_prometheus_javaagent-1.0.1.jar.asc            2024-05-31 03:50       833
# jmx_prometheus_javaagent-1.0.1.jar.md5            2024-05-31 03:50        32
# jmx_prometheus_javaagent-1.0.1.jar.sha1           2024-05-31 03:50        40
# 2. add the jar to the spark_py_image once dev is finished
# Add the Prometheus JMX exporter Java agent jar for exposing metrics sent to the JmxSink to Prometheus.
# 3. Update the version of the JMX exporter agent if needed to v1.0.1 (latest)
ENV JMX_EXPORTER_AGENT_VERSION=1.1.0
ADD https://github.com/prometheus/jmx_exporter/releases/download/${JMX_EXPORTER_AGENT_VERSION}/jmx_prometheus_javaagent-${JMX_EXPORTER_AGENT_VERSION}.jar /opt/spark/jars
RUN chmod 644 /opt/spark/jars/jmx_prometheus_javaagent-${JMX_EXPORTER_AGENT_VERSION}.jar

# Main process will run as spark_uid
# RW access to $HOME/.conda my be required for miniconda install (at least for version py311_25.1.1-2)
ENV HOME=/home/fink-broker
RUN mkdir -p $HOME && chown ${spark_uid} $HOME

WORKDIR $HOME

USER ${spark_uid}

# Copy survey-specific files and install scripts
ADD --chown=${spark_uid} containerfs/${input_survey}/ $FINK_BROKER_ROOT/${input_survey}/
ADD --chown=${spark_uid} containerfs/install_python_deps.sh $FINK_BROKER_ROOT/
ADD --chown=${spark_uid} containerfs/install_miniconda.sh $FINK_BROKER_ROOT/

# Install python using survey-specific version
RUN source $FINK_BROKER_ROOT/${input_survey}/python_version.sh && \
    $FINK_BROKER_ROOT/install_miniconda.sh --version ${PYTHON_VERSION}

ENV PATH=$FINK_BROKER_ROOT/miniconda/bin:$PATH

# Avoid re-installing Python dependencies when fink-broker code changes
ENV PIP_NO_CACHE_DIR=1

# Install noscience dependencies using unified script
RUN $FINK_BROKER_ROOT/install_python_deps.sh --survey ${input_survey} --noscience --verbose


# TODO add a development image which include tools below
# doctest requirements
# example: python $FINK_BROKER_ROOT/fink_broker/science.py
RUN pip install py4j


FROM noscience AS science

# Avoid re-installing Python dependencies when fink-broker code changes
ENV PIP_NO_CACHE_DIR=1

# Install science dependencies using unified script (files already copied from containerfs)
RUN $FINK_BROKER_ROOT/install_python_deps.sh --survey ${input_survey} --science --verbose
